{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbfe2214",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import tensor\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from opt_einsum import contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a45e7fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ae_loss(ref_dict,pred_dict, loss, **kwargs):\n",
    "    \"\"\"ae_loss(ref_dict, pred_dict, loss, **kwargs):\n",
    "    \n",
    "        Calulates atomization energy loss from reference values.\n",
    "\n",
    "    Args:\n",
    "        ref_dict ([dict]): A dictionary of reference atomization energies, whose values are flattened to a list.\n",
    "        pred_dict ([dict]): A dictionary of predicted atomization energies, whose values are flattened to a list.\n",
    "        loss (callable): Callable loss function\n",
    "        weights (torch.Tensor) [optional]: if specified, scale individual energy differences.\n",
    "            defaults to a linspace of weights from 0 to 1 of size results['E'], or 1 if only one prediction.\n",
    "\n",
    "    Returns:\n",
    "        [?]: loss called on weighted difference between reference and prediction\n",
    "    \"\"\"\n",
    "    print(\"AE_LOSS FUNCTION\")\n",
    "    print(\"INPUT REF/PRED: \")\n",
    "    print(\"REF: {}\".format(ref_dict))\n",
    "    print(\"PRED: {}\".format(pred_dict))\n",
    "    print(\"Flattening ref_dict, pred_dict\")\n",
    "    #ref = torch.cat(list(atomization_energies(ref_dict).values()))\n",
    "    atm_pred = atomization_energies(pred_dict)\n",
    "    ref = ref_dict[list(atm_pred.keys())[0]]\n",
    "    pred = torch.cat(list(atm_pred.values()))\n",
    "    assert len(ref) == 1\n",
    "    ref = ref.expand(pred.size()[0])\n",
    "    if pred.size()[0] > 1:\n",
    "        weights = kwargs.get('weights', torch.linspace(0,1,pred.size()[0])**2).to(pred.device)\n",
    "    else:\n",
    "        weights = 1\n",
    "    lae = loss((ref-pred)*weights,torch.zeros_like(pred))\n",
    "    print(\"AE LOSS: {}\".format(lae))\n",
    "    return lae\n",
    "\n",
    "\n",
    "def atomization_energies(energies):\n",
    "    \"\"\"Calculates atomization energies based on a dictionary of molecule/atomic energies.\n",
    "    \n",
    "    energies['ABCD'] = molecular energy\n",
    "    energies['A'], energies['B'], etc. = atomic energy.\n",
    "    \n",
    "    Loops over ABCD - A - B - C - D\n",
    "\n",
    "    Args:\n",
    "        energies (dict): dictionary of molecule and constituent atomic energies.\n",
    "    \"\"\"\n",
    "    def split(el):\n",
    "        \"\"\"Regex split molecule's symbolic expansion into constituent elements.\n",
    "        No numbers must be present -- CH2 = CHH.\n",
    "\n",
    "        Args:\n",
    "            el (str): Molecule symbols\n",
    "\n",
    "        Returns:\n",
    "            list: list of individual atoms in molecule\n",
    "        \"\"\"\n",
    "        import re\n",
    "        res_list = [s for s in re.split(\"([A-Z][^A-Z]*)\", el) if s]\n",
    "        return res_list\n",
    "\n",
    "\n",
    "    ae = {}\n",
    "    for key in energies:\n",
    "        if isinstance(energies[key],torch.Tensor):\n",
    "            #if len(split(key)) == 1:continue\n",
    "            e_tot = torch.clone(energies[key])\n",
    "            e_tot_size = e_tot.size()\n",
    "        else:\n",
    "            e_tot = np.array(energies[key])\n",
    "            e_tot_size = e_tot.shape\n",
    "        for symbol in split(key):\n",
    "            #if single atom, continue\n",
    "            if len(split(key)) == 1: continue\n",
    "            e_sub = energies[symbol]\n",
    "            e_sub_size = e_sub.size() if isinstance(e_sub, torch.Tensor) else e_sub.shape\n",
    "            if e_tot_size == e_sub_size:\n",
    "                e_tot -= e_sub\n",
    "            else:\n",
    "                e_tot -= e_sub[-1:]\n",
    "            print('{} - {}: {}'.format(key, symbol, e_tot))\n",
    "            ae[key] = e_tot\n",
    "    if ae == {}:\n",
    "        #empty dict -- no splitting occurred, so single atom\n",
    "        ae[key] = e_tot\n",
    "    print(\"Atomization Energy Final\")\n",
    "    print(ae)\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6d53ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCHH - C: tensor([-39.3797, -39.3795, -39.3794, -39.3793, -39.3793, -39.3793, -39.3792,\n",
      "        -39.3792, -39.3792, -39.3792])\n",
      "CCHH - C: tensor([-1.5942, -1.5939, -1.5937, -1.5936, -1.5936, -1.5936, -1.5934, -1.5934,\n",
      "        -1.5934, -1.5934])\n",
      "CCHH - H: tensor([-1.0977, -1.0973, -1.0971, -1.0969, -1.0969, -1.0969, -1.0966, -1.0966,\n",
      "        -1.0966, -1.0966])\n",
      "CCHH - H: tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])\n",
      "Atomization Energy Final\n",
      "{'CCHH': tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'CCHH': tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
       "         -0.5998, -0.5998])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = {'CCHH': tensor([-0.6459]), 'C': tensor([-37.8405]), 'H': tensor([-0.5000])}\n",
    "pd = {'CCHH': tensor([-77.1652, -77.1651, -77.1651, -77.1650, -77.1650, -77.1650, -77.1650,\n",
    "        -77.1650, -77.1650, -77.1650]), 'C': tensor([-37.7855, -37.7856, -37.7857, -37.7857, -37.7857, -37.7857, -37.7858,\n",
    "        -37.7858, -37.7858, -37.7858]), 'H': tensor([-0.4965, -0.4966, -0.4966, -0.4967, -0.4967, -0.4967, -0.4968, -0.4968,\n",
    "        -0.4968, -0.4968])}\n",
    "atomization_energies(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae386500",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_loss = partial(ae_loss,loss = torch.nn.MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03d38693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE_LOSS FUNCTION\n",
      "INPUT REF/PRED: \n",
      "REF: {'CCHH': tensor([-0.6459]), 'C': tensor([-37.8405]), 'H': tensor([-0.5000])}\n",
      "PRED: {'CCHH': tensor([-77.1652, -77.1651, -77.1651, -77.1650, -77.1650, -77.1650, -77.1650,\n",
      "        -77.1650, -77.1650, -77.1650]), 'C': tensor([-37.7855, -37.7856, -37.7857, -37.7857, -37.7857, -37.7857, -37.7858,\n",
      "        -37.7858, -37.7858, -37.7858]), 'H': tensor([-0.4965, -0.4966, -0.4966, -0.4967, -0.4967, -0.4967, -0.4968, -0.4968,\n",
      "        -0.4968, -0.4968])}\n",
      "Flattening ref_dict, pred_dict\n",
      "CCHH - C: tensor([-39.3797, -39.3795, -39.3794, -39.3793, -39.3793, -39.3793, -39.3792,\n",
      "        -39.3792, -39.3792, -39.3792])\n",
      "CCHH - C: tensor([-1.5942, -1.5939, -1.5937, -1.5936, -1.5936, -1.5936, -1.5934, -1.5934,\n",
      "        -1.5934, -1.5934])\n",
      "CCHH - H: tensor([-1.0977, -1.0973, -1.0971, -1.0969, -1.0969, -1.0969, -1.0966, -1.0966,\n",
      "        -1.0966, -1.0966])\n",
      "CCHH - H: tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])\n",
      "Atomization Energy Final\n",
      "{'CCHH': tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])}\n",
      "AE LOSS: 0.000496126536745578\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_loss(rd, pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dfbabb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOO - N: tensor([-150.3218])\n",
      "NOO - O: tensor([-75.3454])\n",
      "NOO - O: tensor([-0.3690])\n",
      "Atomization Energy Final\n",
      "{'NOO': tensor([-0.3690])}\n",
      "AE_LOSS FUNCTION\n",
      "INPUT REF/PRED: \n",
      "REF: {'NOO': tensor([-0.3634]), 'N': tensor([-54.5892]), 'O': tensor([-75.0673])}\n",
      "PRED: {'NOO': tensor([-204.8356]), 'N': tensor([-54.5133, -54.5134, -54.5136, -54.5137, -54.5137, -54.5138, -54.5138,\n",
      "        -54.5138, -54.5138, -54.5138]), 'O': tensor([-74.9761, -74.9762, -74.9762, -74.9763, -74.9763, -74.9764, -74.9764,\n",
      "        -74.9764, -74.9764, -74.9764])}\n",
      "Flattening ref_dict, pred_dict\n",
      "NOO - N: tensor([-150.3218])\n",
      "NOO - O: tensor([-75.3454])\n",
      "NOO - O: tensor([-0.3690])\n",
      "Atomization Energy Final\n",
      "{'NOO': tensor([-0.3690])}\n",
      "AE LOSS: 3.139678665320389e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(3.1397e-05)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = {'NOO': tensor([-0.3634]), 'N': tensor([-54.5892]), 'O': tensor([-75.0673])}\n",
    "pd = {'NOO': tensor([-204.8356]), 'N': tensor([-54.5133, -54.5134, -54.5136, -54.5137, -54.5137, -54.5138, -54.5138,\n",
    "        -54.5138, -54.5138, -54.5138]), 'O': tensor([-74.9761, -74.9762, -74.9762, -74.9763, -74.9763, -74.9764, -74.9764,\n",
    "        -74.9764, -74.9764, -74.9764])}\n",
    "atomization_energies(pd)\n",
    "ae_loss(rd, pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "778642fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OHH - O: tensor([-1.3514])\n",
      "OHH - H: tensor([-0.8545])\n",
      "OHH - H: tensor([-0.3576])\n",
      "Atomization Energy Final\n",
      "{'OHH': tensor([-0.3576])}\n",
      "AE_LOSS FUNCTION\n",
      "INPUT REF/PRED: \n",
      "REF: {'OHH': tensor([-0.3713]), 'O': tensor([-75.0673]), 'H': tensor([-0.5000])}\n",
      "PRED: {'OHH': tensor([-76.3291]), 'O': tensor([-74.9773, -74.9774, -74.9775, -74.9776, -74.9776, -74.9776, -74.9776,\n",
      "        -74.9776, -74.9777, -74.9777]), 'H': tensor([-0.4966, -0.4967, -0.4967, -0.4968, -0.4968, -0.4969, -0.4969, -0.4969,\n",
      "        -0.4969, -0.4969])}\n",
      "Flattening ref_dict, pred_dict\n",
      "OHH - O: tensor([-1.3514])\n",
      "OHH - H: tensor([-0.8545])\n",
      "OHH - H: tensor([-0.3576])\n",
      "Atomization Energy Final\n",
      "{'OHH': tensor([-0.3576])}\n",
      "AE LOSS: 0.00018762654508464038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0002)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rd = {'OHH': tensor([-0.3713]), 'O': tensor([-75.0673]), 'H': tensor([-0.5000])}\n",
    "pd = {'OHH': tensor([-76.3291]), 'O': tensor([-74.9773, -74.9774, -74.9775, -74.9776, -74.9776, -74.9776, -74.9776,\n",
    "        -74.9776, -74.9777, -74.9777]), 'H': tensor([-0.4966, -0.4967, -0.4967, -0.4968, -0.4968, -0.4969, -0.4969, -0.4969,\n",
    "        -0.4969, -0.4969])}\n",
    "atomization_energies(pd)\n",
    "ae_loss(rd, pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3f63af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CCHH - C: tensor([-39.3797, -39.3795, -39.3794, -39.3793, -39.3793, -39.3793, -39.3792,\n",
      "        -39.3792, -39.3792, -39.3792])\n",
      "CCHH - C: tensor([-1.5942, -1.5939, -1.5937, -1.5936, -1.5936, -1.5936, -1.5934, -1.5934,\n",
      "        -1.5934, -1.5934])\n",
      "CCHH - H: tensor([-1.0977, -1.0973, -1.0971, -1.0969, -1.0969, -1.0969, -1.0966, -1.0966,\n",
      "        -1.0966, -1.0966])\n",
      "CCHH - H: tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])\n",
      "Atomization Energy Final\n",
      "{'CCHH': tensor([-0.6012, -0.6007, -0.6005, -0.6002, -0.6002, -0.6002, -0.5998, -0.5998,\n",
      "        -0.5998, -0.5998])}\n"
     ]
    }
   ],
   "source": [
    "t = atomization_energies(pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "496f1f54",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict_keys' object has no attribute 'values'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_31084/2587436144.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict_keys' object has no attribute 'values'"
     ]
    }
   ],
   "source": [
    "t.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b5ecfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
